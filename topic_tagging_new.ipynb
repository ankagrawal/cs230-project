{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 395
    },
    "id": "tezCeoI1f5zR",
    "outputId": "c830eafc-7e0b-4888-d5ec-290116e5a691",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import io\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "\n",
    "DATA_DIR=\"data/\"\n",
    "WORD2VEC_BIN_PATH=DATA_DIR+\"SO_vectors_200.bin\"\n",
    "ANSWERS_CSV_PATH=DATA_DIR+\"Answers.csv\"\n",
    "QUESTIONS_CSV_PATH=DATA_DIR+\"Questions.csv\"\n",
    "TAGS_CSV_PATH=DATA_DIR+\"Tags.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "GELHeMMQiYWi",
    "outputId": "2a914c25-d5a2-4edc-8f02-45b557e71647"
   },
   "outputs": [],
   "source": [
    "word_vect = KeyedVectors.load_word2vec_format(WORD2VEC_BIN_PATH, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "a0-p5nxjf5zU"
   },
   "outputs": [],
   "source": [
    "idToTagIndex = {}          #dict mapping post ID to a list of tag indices\n",
    "tagToTagIndex = {}         #dict mapping tag to tag index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "fTWE-sVdf5zW"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "def truncate(number, digits) -> float:\n",
    "    stepper = 10.0 ** digits\n",
    "    return math.trunc(stepper * number) / stepper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "id": "jFSErmPHf5zY",
    "outputId": "1b2c8ca3-3c56-4493-9a9b-d8260039a839"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Id', 'OwnerUserId', 'CreationDate', 'ClosedDate', 'Score', 'Title',\n",
      "       'Body'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "questions_data = None\n",
    "with io.open(QUESTIONS_CSV_PATH, 'r',encoding='utf-8',errors='ignore') as question_input:\n",
    "    questions_data = pd.read_csv(question_input, engine='python')\n",
    "\n",
    "print(questions_data.columns)\n",
    "questions_data = questions_data[['Id', 'Title', 'Body']]\n",
    "questions_data.insert(len(questions_data.columns), 'Code', \"\")\n",
    "\n",
    "a = re.compile(r'<pre><code>([^<]*)</code></pre>')\n",
    "b = re.compile(r'<.*?>')\n",
    "questions_data['Code'] = questions_data['Body'].apply(lambda x: ' '.join(re.findall(a, x)))\n",
    "\n",
    "def clean(text):\n",
    "    x = re.sub(a, '', text)\n",
    "    x = re.sub(b, '', x)\n",
    "    x = x.replace('\\n\\n', '\\n')\n",
    "    return x\n",
    "questions_data['Body'] = questions_data['Title'].str.cat(questions_data['Body'], sep=\" \")\n",
    "questions_data['Body'] = questions_data['Body'].apply(clean)\n",
    "    \n",
    "#     questions_data['Body'] = questions_data['Body'].apply(nltk.tokenize.word_tokenize) #need to fix: don't convert\n",
    "#     # C#, C++ to C\n",
    "#     questions_data['Body'] = questions_data['Body'].apply(lambda x: [word for word in x if word.  isalnum()])\n",
    "#     questions_data['Body'] = questions_data['Body'].apply(lambda x: [word.lower() for word in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "MNtzVO2Df5zc",
    "outputId": "3dd1ee34-3560-4033-987e-0d441c7eaaf5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3750994it [09:31, 6562.73it/s]\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "idToTagIndex = {}          #dict mapping post ID to a list of tag indices\n",
    "tagToTagIndex = {}         #dict mapping tag to tag index\n",
    "tagIndexToTag = {}\n",
    "tagToFrequency = defaultdict(lambda: 0)\n",
    "\n",
    "with open(TAGS_CSV_PATH) as tag_input:\n",
    "    tag_data = pd.read_csv(tag_input)\n",
    "    tagIndex = 0\n",
    "    for index, row in tqdm(tag_data.iterrows()):\n",
    "        currId = int(row[0])\n",
    "        currTag = row[1]\n",
    "        if currTag not in tagToTagIndex:\n",
    "            tagToTagIndex[currTag] = tagIndex\n",
    "            tagIndexToTag[tagIndex] = currTag\n",
    "            currTagIndex = tagIndex\n",
    "            tagIndex += 1\n",
    "\n",
    "        else:\n",
    "            currTagIndex = tagToTagIndex[currTag]  \n",
    "        \n",
    "        tagToFrequency[currTagIndex] += 1        \n",
    "    \n",
    "        if currId not in idToTagIndex.keys():\n",
    "            idToTagIndex[currId] = [tagToTagIndex[row[1]]]\n",
    "        else:\n",
    "            idToTagIndex[currId].append(tagToTagIndex[row[1]])\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "vFNFrh0of5ze",
    "outputId": "2916eab7-7b87-4973-f46f-a77e272909ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of examples:  1264216\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of examples: \", len(idToTagIndex))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 287
    },
    "id": "s66KeGgCf5zh",
    "outputId": "eb5b0e38-1c01-4db9-e177-989223674bd5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "javascript (132): 124155 times\n",
      "java (89): 115212 times\n",
      "c# (14): 101186 times\n",
      "php (76): 98808 times\n",
      "android (395): 90659 times\n",
      "jquery (370): 78542 times\n",
      "python (196): 64601 times\n",
      "html (58): 58976 times\n",
      "c++ (18): 47591 times\n",
      "ios (2045): 47009 times\n",
      "mysql (77): 42464 times\n",
      "css (141): 42308 times\n",
      "sql (7): 35782 times\n",
      "asp.net (8): 29970 times\n",
      "objective-c (163): 26922 times\n"
     ]
    }
   ],
   "source": [
    "# find 10 most common tags\n",
    "\n",
    "n = 15      #number of top tags\n",
    "\n",
    "tagToFrequencyList = []\n",
    "\n",
    "for key, value in tagToFrequency.items():\n",
    "    temp = [key, value]\n",
    "    tagToFrequencyList.append(temp)\n",
    "    \n",
    "tagToFrequencyList.sort(reverse=True, key=lambda x: x[1])\n",
    "\n",
    "for tag in tagToFrequencyList[:n]:\n",
    "    print(f\"{tagIndexToTag[tag[0]]} ({tag[0]}): {tag[1]} times\")\n",
    "    \n",
    "mostCommonTags = {}\n",
    "for counter, tag in enumerate(tagToFrequencyList[:n]):   #currently takes top 10 tags\n",
    "    mostCommonTags[tag[0]] = counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "gQ-IB6abf5zk",
    "outputId": "1f9364ec-6f57-42ee-ee9c-7ebd2b774f1b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{132: 0, 89: 1, 14: 2, 76: 3, 395: 4, 370: 5, 196: 6, 58: 7, 18: 8, 2045: 9, 77: 10, 141: 11, 7: 12, 8: 13, 163: 14}\n"
     ]
    }
   ],
   "source": [
    "# list(idToTagIndex.values())[:10]\n",
    "print(mostCommonTags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "id": "7uDtvzyRf5zm",
    "outputId": "0df1ac97-8df4-445b-d28e-7be1baafd18c",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Id                                              Title  \\\n",
      "0              80  SQLStatement.execute() - multiple queries in o...   \n",
      "1              90  Good branching and merging tutorials for Torto...   \n",
      "2             120                                  ASP.NET Site Maps   \n",
      "3             180                 Function for creating color wheels   \n",
      "4             260  Adding scripting functionality to .NET applica...   \n",
      "...           ...                                                ...   \n",
      "1264211  40143210                           URL routing in PHP (MVC)   \n",
      "1264212  40143300           Bigquery.Jobs.Insert - Resumable Upload?   \n",
      "1264213  40143340                 Obfuscating code in android studio   \n",
      "1264214  40143360         How to fire function after v-model change?   \n",
      "1264215  40143380            npm run mocha test - files being cached   \n",
      "\n",
      "                                                      Body  \\\n",
      "0        SQLStatement.execute() - multiple queries in o...   \n",
      "1        Good branching and merging tutorials for Torto...   \n",
      "2        ASP.NET Site Maps Has anyone got experience cr...   \n",
      "3        Function for creating color wheels This is som...   \n",
      "4        Adding scripting functionality to .NET applica...   \n",
      "...                                                    ...   \n",
      "1264211  URL routing in PHP (MVC) I am building a custo...   \n",
      "1264212  Bigquery.Jobs.Insert - Resumable Upload? The A...   \n",
      "1264213  Obfuscating code in android studio Under minif...   \n",
      "1264214  How to fire function after v-model change? I h...   \n",
      "1264215  npm run mocha test - files being cached I'm ru...   \n",
      "\n",
      "                                                      Code  Top-Tags  \n",
      "0        Create Table tRole (\\n      roleID integer Pri...        []  \n",
      "1                                                                 []  \n",
      "2                                                           [12, 13]  \n",
      "3                                                                 []  \n",
      "4        ICard Cards[current] = new MyGame.CardLibrary....       [2]  \n",
      "...                                                    ...       ...  \n",
      "1264211  &lt;IfModule mod_rewrite.c&gt;\\n\\nRewriteEngin...       [3]  \n",
      "1264212  AbstractInputStreamContent content = new ByteA...        []  \n",
      "1264213  buildTypes {\\n    release {\\n        minifyEna...       [4]  \n",
      "1264214  var articlesVM = new Vue({\\n      el: '#search...       [0]  \n",
      "1264215  package.json\\n\"test\": \"cross-env NODE_ENV=test...        []  \n",
      "\n",
      "[1264216 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "idToTenTags = {}\n",
    "\n",
    "for postId, tags in idToTagIndex.items():\n",
    "    containsTopTenTags = [mostCommonTags[tag] for tag in tags if tag in mostCommonTags.keys()]\n",
    "    idToTenTags[postId] = containsTopTenTags\n",
    "    \n",
    "questions_data['Top-Tags'] = questions_data['Id'].apply(lambda x: idToTenTags[x])\n",
    "\n",
    "print(questions_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<TensorSliceDataset shapes: (), types: tf.string>\n",
      "WARNING:tensorflow:5 out of the last 2474 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fc50576f9e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 10804.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "num_tokens: 7\n",
      "Converted 3 words (2 misses)\n",
      "[[ 0.          0.          0.         ...  0.          0.\n",
      "   0.        ]\n",
      " [ 0.          0.          0.         ...  0.          0.\n",
      "   0.        ]\n",
      " [ 2.85269427  0.34682763  1.36381459 ...  2.50019026  4.65356922\n",
      "  -1.35075629]\n",
      " ...\n",
      " [ 2.30001998  0.05065627  3.62873197 ...  1.7731936   1.27082145\n",
      "  -0.52977061]\n",
      " [ 0.          0.          0.         ...  0.          0.\n",
      "   0.        ]\n",
      " [ 0.          0.          0.         ...  0.          0.\n",
      "   0.        ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "text_dataset = tf.data.Dataset.from_tensor_slices([\"foo\", \"bar\", \"baz\"])\n",
    "print(text_dataset)\n",
    "#text_ds = tf.data.Dataset.from_tensor_slices(questions_data['Body'].values.tolist())\n",
    "#print(text_ds)\n",
    "max_features = 5000  # Maximum vocab size.\n",
    "max_len = 4  # Sequence length to pad the outputs to.\n",
    "embedding_dims = 2\n",
    "\n",
    "# Create the layer.\n",
    "#vectorize_layer = TextVectorization(\n",
    "# max_tokens=max_features,\n",
    "# output_mode='int',\n",
    "# output_sequence_length=max_len)\n",
    "\n",
    "vectorize_layer = TextVectorization(max_tokens=20000, output_sequence_length=200)\n",
    "vectorize_layer.adapt(text_dataset.batch(64))\n",
    "\n",
    "input_data = [[\"foo qux bar\"], [\"qux baz\"]]\n",
    "questions_X = np.ndarray(shape=(2, 200))\n",
    "questions_X = vectorize_layer([[\"foo qux bar\"]]).numpy()\n",
    "a = vectorize_layer([[\"qux baz\"]]).numpy()\n",
    "#print(\"A: \" + str(a))\n",
    "#print(\"qx: \" + str(questions_X))\n",
    "questions_X = np.append(questions_X, a)\n",
    "#print(questions_X)\n",
    "#print(type(questions_X))\n",
    "\n",
    "# Now that the vocab layer has been created, call `adapt` on the text-only\n",
    "# dataset to create the vocabulary. You don't have to batch, but for large\n",
    "# datasets this means we're not keeping spare copies of the dataset.\n",
    "#vectorize_layer.adapt(text_dataset.batch(64))\n",
    "\n",
    "# Create the model that uses the vectorize text layer\n",
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "# Start by creating an explicit input layer. It needs to have a shape of\n",
    "# (1,) (because we need to guarantee that there is exactly one string\n",
    "# input per batch), and the dtype needs to be 'string'.\n",
    "model.add(tf.keras.Input(shape=(1,), dtype=tf.string))\n",
    "\n",
    "# The first layer in our model is the vectorization layer. After this\n",
    "# layer, we have a tensor of shape (batch_size, max_len) containing vocab\n",
    "# indices.\n",
    "model.add(vectorize_layer)\n",
    "\n",
    "# Now, the model can map strings to integers, and you can add an embedding\n",
    "# layer to map these integers to learned embeddings.\n",
    "input_data = [[\"foo qux bar\"], [\"qux baz\"]]\n",
    "q = model.predict(input_data, batch_size=2)\n",
    "#print(q)\n",
    "#q.numpy()\n",
    "\n",
    "voc = vectorize_layer.get_vocabulary()\n",
    "print(len(voc))\n",
    "word_index = dict(zip(voc, range(len(voc))))\n",
    "\n",
    "num_tokens = len(voc) + 2\n",
    "embedding_dim = 200\n",
    "hits = 0\n",
    "misses = 0\n",
    "missed_words = []\n",
    "print(\"num_tokens: \" + str(num_tokens))\n",
    "\n",
    "embedding_matrix = np.zeros((num_tokens, embedding_dim))\n",
    "for word, i in tqdm(word_index.items()):\n",
    "    try:\n",
    "        embedding_vector = word_vect.get_vector(word)\n",
    "        # Words not found in embedding index will be all-zeros.\n",
    "        # This includes the representation for \"padding\" and \"OOV\"\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "        #if hits == 0:\n",
    "            #print(\"word: \" + word)\n",
    "            #print(\"embedding vector: \" + str(embedding_vector))\n",
    "        hits += 1\n",
    "    except:\n",
    "        misses += 1\n",
    "        missed_words.append(word)\n",
    "print(\"Converted %d words (%d misses)\" % (hits, misses))\n",
    "#print(\"missed words: \" + str(missed_words))\n",
    "print(embedding_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "YiJO2K-Nf5zp",
    "outputId": "06d6b7c9-d803-4c64-94ee-aaae87cd474d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', '[UNK]', 'the', 'i', 'to', 'a', 'is', 'in', 'and', 'of']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "\n",
    "vectorizer = TextVectorization(max_tokens=20000, output_sequence_length=200)\n",
    "text_ds = tf.data.Dataset.from_tensor_slices(questions_data['Body'].values.tolist())\n",
    "vectorizer.adapt(text_ds.batch(512))\n",
    "vectorizer.get_vocabulary()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 107
    },
    "id": "6Ow1zCahf5zr",
    "outputId": "9ab8b3e5-be1b-48c3-dd7d-7d3c89d021d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "input data created\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fc505a4fe60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "[[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 1 1 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "mlb = MultiLabelBinarizer()\n",
    "\n",
    "numex = 0\n",
    "print()\n",
    "#questions_X = vectorizer(np.array([[s] for s in questions_data['Body'].values])).numpy()\n",
    "\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.Input(shape=(1,), dtype=tf.string))\n",
    "model.add(vectorizer) \n",
    "input_data = np.array([[s] for s in questions_data['Body'].values])\n",
    "print(\"input data created\")\n",
    "questions_X = model.predict(input_data, batch_size=512)\n",
    "\n",
    "\n",
    "# Now, the model can map strings to integers, and you can add an embedding\n",
    "# layer to map these integers to learned embeddings.\n",
    "input_data = [[\"foo qux bar\"], [\"qux baz\"]]\n",
    "model.predict(input_data, batch_size=2)\n",
    "\n",
    "\n",
    "questions_y = mlb.fit_transform(np.array(questions_data['Top-Tags'].values))\n",
    "print(questions_y[:5])\n",
    "\n",
    "train_X, test_X, train_y, test_y = train_test_split(questions_X, questions_y, train_size=0.80, random_state=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2]\n"
     ]
    }
   ],
   "source": [
    "print(questions_data['Top-Tags'][4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 359
    },
    "id": "cNgaQhSnf5zu",
    "outputId": "f7d58e19-486f-4b1a-f41b-50cbe17432eb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   3,   80,  182,   10,  139,    9,   29,   17,   31, 1448,    5,\n",
       "         330,  770,  276,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = vectorizer([[\"I tried running this line of code, but I'm receiving a null pointer exception\"]])\n",
    "output.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "id": "fPevRpOZf5zx"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000\n"
     ]
    }
   ],
   "source": [
    "voc = vectorizer.get_vocabulary()\n",
    "print(len(voc))\n",
    "word_index = dict(zip(voc, range(len(voc))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "zgVrfFURf5z1",
    "outputId": "c7fc6591-c583-4933-e3b4-e60a70a84ded"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10, 139, 9, 29]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = [\"this\", \"line\", \"of\", \"code\"]\n",
    "[word_index[w] for w in test] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "4bKb_oCif5z3",
    "outputId": "d4f3f77e-6452-4773-8b22-873633167391"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20000/20000 [00:00<00:00, 261831.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 18902 words (1098 misses)\n",
      "[ 1.11054885e+00 -1.90948397e-01  1.01150262e+00 -1.16011727e+00\n",
      " -4.01061118e-01 -1.99401509e-02  1.26393306e+00 -1.05262327e+00\n",
      " -7.08893120e-01 -1.16170633e+00 -3.82255346e-01 -6.64718449e-01\n",
      "  2.39925131e-01 -9.89318669e-01  4.03541863e-01 -3.09030920e-01\n",
      " -8.93009543e-01  1.47940707e+00  3.45112324e-01 -5.33240616e-01\n",
      " -2.03384962e-02 -8.17787588e-01 -3.95911753e-01 -1.00960648e+00\n",
      "  1.45841193e+00 -1.91910848e-01  1.96030110e-01 -4.74538594e-01\n",
      "  2.30615154e-01 -1.33799136e+00 -7.01056361e-01 -8.22254896e-01\n",
      " -1.97593376e-01 -9.74523842e-01 -1.74921310e+00 -7.13844419e-01\n",
      "  1.00619650e+00  1.94554651e+00  5.25697649e-01  2.44234558e-02\n",
      "  1.18549097e+00  1.38673410e-01  1.57413578e+00  1.35944700e+00\n",
      "  4.00970370e-01  9.36624467e-01 -1.38397664e-01  9.08933640e-01\n",
      " -6.06455147e-01  7.80146241e-01  2.07494706e-01 -1.31700456e+00\n",
      " -5.65629125e-01 -7.15693310e-02 -2.10581228e-01  3.94899547e-01\n",
      " -3.96223903e-01  1.25231707e+00  7.13234767e-04 -1.07387686e+00\n",
      "  3.82182449e-01 -3.15159082e-01  5.42144597e-01  9.75028276e-02\n",
      "  8.72579157e-01 -7.08533451e-02  8.72588336e-01  8.07464838e-01\n",
      "  1.15843737e+00  4.22497600e-01  7.92983592e-01  6.57317460e-01\n",
      " -6.05909944e-01  2.36687273e-01 -8.38113949e-02  1.12513947e+00\n",
      " -4.23325330e-01 -3.48065086e-02  2.74652034e-01 -5.28330028e-01\n",
      " -6.29942954e-01 -1.64502752e+00  5.92753589e-01 -1.70310521e+00\n",
      "  9.64569747e-01  7.14162648e-01 -7.84865767e-02  4.18779522e-01\n",
      "  2.15205774e-01 -7.95087397e-01 -1.38275492e+00 -5.74855983e-01\n",
      "  6.79013789e-01 -7.18639791e-01  2.45778590e-01 -7.09440172e-01\n",
      " -1.18521965e+00  1.51959375e-01 -3.89021665e-01 -8.86604130e-01\n",
      " -7.84266353e-01  1.38460267e+00  5.91488302e-01  3.71362716e-01\n",
      " -7.01739848e-01 -1.07326768e-01  1.43242848e+00 -1.38656175e+00\n",
      "  2.41382003e-01 -1.67573547e+00 -1.27770498e-01 -5.10340631e-02\n",
      " -6.53048038e-01 -1.02443802e+00 -3.89851481e-01  8.56945813e-01\n",
      "  1.24775589e-01 -1.21191740e+00  3.71113807e-01 -1.39379606e-01\n",
      "  1.79362446e-01  1.16243005e+00 -8.12165439e-01 -2.91047722e-01\n",
      "  8.56553540e-02 -4.85349655e-01  1.36092079e+00  7.86120653e-01\n",
      "  1.34591341e-01 -6.37420952e-01 -2.51136512e-01  4.09277290e-01\n",
      " -1.28479970e+00 -1.12714791e+00  1.14765251e+00  3.45524907e-01\n",
      "  2.78059721e-01 -2.37703457e-01  8.97531807e-01  3.29023600e-01\n",
      "  9.33233976e-01  3.20358723e-01  5.66378415e-01  3.51016134e-01\n",
      "  1.97261915e-01 -1.62100935e+00  8.86717737e-02  7.60524571e-01\n",
      "  1.00211233e-01 -2.43169174e-01  2.74593406e-03  1.03757691e+00\n",
      " -1.32073891e+00 -7.99644813e-02 -1.38314188e+00 -5.44375300e-01\n",
      " -2.55420536e-01  8.62853974e-02  8.67242754e-01 -3.91934335e-01\n",
      " -3.82347137e-01  2.15594769e-01  1.81583405e-01 -6.73553526e-01\n",
      " -2.71433949e-01 -3.68699968e-01  9.71431136e-01  1.39646590e-01\n",
      "  7.78143704e-01 -1.79461241e-01  3.13333839e-01  5.20481944e-01\n",
      " -5.20747483e-01 -7.21387982e-01  4.72334832e-01 -1.60268891e+00\n",
      "  9.43996608e-02 -3.27122658e-01  6.03518426e-01  2.59867281e-01\n",
      " -2.89306253e-01  1.19505696e-01  1.05794442e+00 -1.01887476e+00\n",
      "  1.08916771e+00 -1.57397377e+00  1.72884214e+00 -4.07356590e-01\n",
      "  9.47476566e-01 -3.83007109e-01 -7.30230868e-01 -1.55322477e-02\n",
      " -2.08836377e-01  1.84831977e-01 -2.55644415e-02 -7.74908781e-01\n",
      " -2.41134930e+00  1.32455155e-01  1.00438321e+00 -1.48081386e+00]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "num_tokens = len(voc) + 2\n",
    "embedding_dim = 200\n",
    "hits = 0\n",
    "misses = 0\n",
    "missed_words = []\n",
    "\n",
    "embedding_matrix = np.zeros((num_tokens, embedding_dim))\n",
    "for word, i in tqdm(word_index.items()):\n",
    "    try:\n",
    "        embedding_vector = word_vect.get_vector(word)\n",
    "        # Words not found in embedding index will be all-zeros.\n",
    "        # This includes the representation for \"padding\" and \"OOV\"\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "        #if hits == 0:\n",
    "            #print(\"word: \" + word)\n",
    "            #print(\"embedding vector: \" + str(embedding_vector))\n",
    "        hits += 1\n",
    "    except:\n",
    "        misses += 1\n",
    "        missed_words.append(word)\n",
    "print(\"Converted %d words (%d misses)\" % (hits, misses))\n",
    "print(word_vect.get_vector(\"qux\"))\n",
    "#print(\"missed words: \" + str(missed_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "id": "_auFfMlnf5z6"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Embedding\n",
    "\n",
    "embedding_layer = Embedding(\n",
    "    num_tokens,\n",
    "    embedding_dim,\n",
    "    embeddings_initializer=keras.initializers.Constant(embedding_matrix),\n",
    "    trainable=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 629
    },
    "id": "8IXE-Ehaf5z8",
    "outputId": "225d1b6d-9ec8-4097-81f2-94ccbd9677c6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_28 (InputLayer)        [(None, None)]            0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, None, 200)         4000400   \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, None, 128)         128128    \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, None, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, None, 128)         82048     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, None, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, None, 128)         82048     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 15)                1935      \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 15)                0         \n",
      "=================================================================\n",
      "Total params: 4,311,071\n",
      "Trainable params: 310,671\n",
      "Non-trainable params: 4,000,400\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "int_sequences_input = keras.Input(shape=(None,), dtype=\"int64\")\n",
    "embedded_sequences = embedding_layer(int_sequences_input)\n",
    "x = layers.Conv1D(128, 5, activation=\"relu\")(embedded_sequences)\n",
    "x = layers.MaxPooling1D(5)(x)\n",
    "x = layers.Conv1D(128, 5, activation=\"relu\")(x)\n",
    "x = layers.MaxPooling1D(5)(x)\n",
    "x = layers.Conv1D(128, 5, activation=\"relu\")(x)\n",
    "x = layers.GlobalMaxPooling1D()(x)\n",
    "x = layers.Dense(128, activation=\"sigmoid\")(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "preds = layers.Dense(len(mostCommonTags))(x) #change to all tags\n",
    "# preds = layers.Softmax(axis=-1)(preds)\n",
    "preds = layers.Activation(activation=\"sigmoid\")(preds)\n",
    "model = keras.Model(int_sequences_input, preds)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 755
    },
    "id": "VUeS4fMzf50A",
    "outputId": "a95d6de2-423b-4dc4-84d5-1b8974331754"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "7902/7902 [==============================] - 196s 25ms/step - loss: 2.2558e-06 - accuracy: 0.1816 - recall_m: 0.0321 - val_loss: 0.1342 - val_accuracy: 0.3389 - val_recall_m: 0.0215\n",
      "Epoch 2/20\n",
      "7902/7902 [==============================] - 195s 25ms/step - loss: 1.5828e-06 - accuracy: 0.3612 - recall_m: 0.1994 - val_loss: 0.1063 - val_accuracy: 0.4385 - val_recall_m: 0.3009\n",
      "Epoch 3/20\n",
      "7902/7902 [==============================] - 195s 25ms/step - loss: 1.3726e-06 - accuracy: 0.4198 - recall_m: 0.3444 - val_loss: 0.0979 - val_accuracy: 0.4598 - val_recall_m: 0.4053\n",
      "Epoch 4/20\n",
      "7902/7902 [==============================] - 195s 25ms/step - loss: 1.2821e-06 - accuracy: 0.4462 - recall_m: 0.4095 - val_loss: 0.0928 - val_accuracy: 0.4797 - val_recall_m: 0.4448\n",
      "Epoch 5/20\n",
      "7902/7902 [==============================] - 195s 25ms/step - loss: 1.2300e-06 - accuracy: 0.4580 - recall_m: 0.4457 - val_loss: 0.0910 - val_accuracy: 0.4760 - val_recall_m: 0.4750\n",
      "Epoch 6/20\n",
      "7902/7902 [==============================] - 195s 25ms/step - loss: 1.1960e-06 - accuracy: 0.4657 - recall_m: 0.4646 - val_loss: 0.0892 - val_accuracy: 0.4925 - val_recall_m: 0.4856\n",
      "Epoch 7/20\n",
      "7902/7902 [==============================] - 195s 25ms/step - loss: 1.1717e-06 - accuracy: 0.4696 - recall_m: 0.4777 - val_loss: 0.0881 - val_accuracy: 0.4985 - val_recall_m: 0.4859\n",
      "Epoch 8/20\n",
      "7902/7902 [==============================] - 195s 25ms/step - loss: 1.1537e-06 - accuracy: 0.4733 - recall_m: 0.4866 - val_loss: 0.0868 - val_accuracy: 0.4934 - val_recall_m: 0.5028\n",
      "Epoch 9/20\n",
      "7902/7902 [==============================] - 195s 25ms/step - loss: 1.1374e-06 - accuracy: 0.4746 - recall_m: 0.4945 - val_loss: 0.0869 - val_accuracy: 0.4863 - val_recall_m: 0.5202\n",
      "Epoch 10/20\n",
      "7902/7902 [==============================] - 195s 25ms/step - loss: 1.1247e-06 - accuracy: 0.4761 - recall_m: 0.5011 - val_loss: 0.0854 - val_accuracy: 0.5024 - val_recall_m: 0.5190\n",
      "Epoch 11/20\n",
      "7902/7902 [==============================] - 195s 25ms/step - loss: 1.1110e-06 - accuracy: 0.4782 - recall_m: 0.5081 - val_loss: 0.0858 - val_accuracy: 0.4924 - val_recall_m: 0.5257\n",
      "Epoch 12/20\n",
      "7902/7902 [==============================] - 195s 25ms/step - loss: 1.0998e-06 - accuracy: 0.4799 - recall_m: 0.5131 - val_loss: 0.0861 - val_accuracy: 0.4830 - val_recall_m: 0.5313\n",
      "Epoch 13/20\n",
      "7902/7902 [==============================] - 195s 25ms/step - loss: 1.0906e-06 - accuracy: 0.4819 - recall_m: 0.5175 - val_loss: 0.0847 - val_accuracy: 0.4884 - val_recall_m: 0.5379\n",
      "Epoch 14/20\n",
      "7902/7902 [==============================] - 195s 25ms/step - loss: 1.0805e-06 - accuracy: 0.4829 - recall_m: 0.5220 - val_loss: 0.0844 - val_accuracy: 0.4917 - val_recall_m: 0.5367\n",
      "Epoch 15/20\n",
      "7902/7902 [==============================] - 195s 25ms/step - loss: 1.0722e-06 - accuracy: 0.4842 - recall_m: 0.5272 - val_loss: 0.0841 - val_accuracy: 0.5081 - val_recall_m: 0.5406\n",
      "Epoch 16/20\n",
      "7902/7902 [==============================] - 195s 25ms/step - loss: 1.0640e-06 - accuracy: 0.4858 - recall_m: 0.5309 - val_loss: 0.0837 - val_accuracy: 0.5004 - val_recall_m: 0.5528\n",
      "Epoch 17/20\n",
      "7902/7902 [==============================] - 195s 25ms/step - loss: 1.0569e-06 - accuracy: 0.4874 - recall_m: 0.5347 - val_loss: 0.0836 - val_accuracy: 0.4966 - val_recall_m: 0.5486\n",
      "Epoch 18/20\n",
      "7902/7902 [==============================] - 195s 25ms/step - loss: 1.0485e-06 - accuracy: 0.4882 - recall_m: 0.5378 - val_loss: 0.0832 - val_accuracy: 0.4993 - val_recall_m: 0.5514\n",
      "Epoch 19/20\n",
      "7902/7902 [==============================] - 195s 25ms/step - loss: 1.0413e-06 - accuracy: 0.4891 - recall_m: 0.5410 - val_loss: 0.0837 - val_accuracy: 0.4993 - val_recall_m: 0.5446\n",
      "Epoch 20/20\n",
      "7902/7902 [==============================] - 195s 25ms/step - loss: 1.0345e-06 - accuracy: 0.4906 - recall_m: 0.5438 - val_loss: 0.0867 - val_accuracy: 0.4851 - val_recall_m: 0.5448\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fc508e427d0>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils import class_weight\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy', recall_m])\n",
    "              # metrics=[recall_m])\n",
    "weights = {}\n",
    "\n",
    "for i in range(n):\n",
    "    weights[i] = (1 / tagToFrequencyList[i][1])\n",
    "\n",
    "model.fit(train_X, train_y, batch_size=128, epochs=20, validation_data=(test_X, test_y), class_weight=weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 361
    },
    "id": "s6NH1sw_f50D",
    "outputId": "dafa8b4f-67bd-4ce2-d469-e210a1607963"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fc509d593b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "javascript        0.0             \n",
      "java              0.031           \n",
      "c#                0.005           \n",
      "php               0.0             \n",
      "android           0.275           \n",
      "jquery            0.0             \n",
      "python            0.0             \n",
      "html              0.0             \n",
      "c++               0.001           \n",
      "ios               0.241           \n",
      "mysql             0.0             \n",
      "css               0.0             \n",
      "sql               0.0             \n",
      "asp.net           0.0             \n",
      "objective-c       0.118           \n",
      "\n",
      "Most likely tag: android\n"
     ]
    }
   ],
   "source": [
    "string_input = keras.Input(shape=(1,), dtype=\"string\")\n",
    "x = vectorizer(string_input)\n",
    "preds = model(x)\n",
    "end_to_end_model = keras.Model(string_input, preds)\n",
    "\n",
    "probabilities = end_to_end_model.predict(\n",
    "    #[\"I wanted to open my app without safari system alert but I found out that is impossible. so i decided to handle this alert event but I couldn't find the way. if I click [open], then safari open App, but if I click [cancel], then 'appCheckTimer' will be executed, then safari moves to 'some page's url'. if there is no way to not open this alert, I want to handle this alert's button event, when user click [cancel], I just want to stay that page. that alert is not opened by me, it's by safari So I can't handle it.\"]\n",
    "    # [\"My sorting algorithm time is fast\"]\n",
    "    # [\"I try to create a person detection model with Tensorflow object detection api. I'm using Tensorflow 2. But at the end, the model has poor accuracy. It is detecting persons on image, but it only predicts between 30-60%.\"]\n",
    "    #[\"Using Linux mint which has multiple packages installed. I have installed opencv and imutils using sudo pip3 install opencv and sudo pip3 install imutils.\"]\n",
    "    #[\"How does system.out.println work in java?\"]\n",
    "    #[\"Questions about Collections\"]\n",
    "    [\"How to install an app from app store\"]\n",
    ")\n",
    "\n",
    "for i, prob in np.ndenumerate(probabilities):\n",
    "    print('{:<16}  {:<16}'.format(tagIndexToTag[tagToFrequencyList[i[1]][0]], truncate(prob, 3)))\n",
    "print(f\"\\nMost likely tag: {tagIndexToTag[tagToFrequencyList[np.argmax(probabilities)][0]]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 242
    },
    "id": "bIH44Q01AG5q",
    "outputId": "32bdd7c4-23da-494d-e641-d5c55a2940f2"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-d09f22b0d3d4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredictions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpadded_docs_test\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mthresholds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.6\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.7\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthresholds\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mpred\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'padded_docs_test' is not defined"
     ]
    }
   ],
   "source": [
    "# predictions=model.predict([padded_docs_test])\n",
    "# thresholds=[0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]\n",
    "# for val in thresholds:\n",
    "#     pred=predictions.copy()\n",
    "  \n",
    "#     pred[pred>=val]=1\n",
    "#     pred[pred<val]=0\n",
    "  \n",
    "#     precision = precision_score(y_test, pred, average='micro')\n",
    "#     recall = recall_score(y_test, pred, average='micro')\n",
    "#     f1 = f1_score(y_test, pred, average='micro')\n",
    "   \n",
    "#     print(\"Micro-average quality numbers\")\n",
    "#     print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "topic-tagging.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow2_latest_p37)",
   "language": "python",
   "name": "conda_tensorflow2_latest_p37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
